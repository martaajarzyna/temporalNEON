---
title: "Tidy NEON Macroinvertebrates Data"
output: rmarkdown::html_vignette
author: Mariana Perez Rocha, Matthew R. Helmus
vignette: >
  %\VignetteIndexEntry{Tidy NEON Macroinvertebrates Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Aims and Scope
The aim of this document is to download and tidy data for Temporal NEON WG 14 Project.

## Setup

```{r packages, include=FALSE}
#library(temporalNEON)
library(devtools)
library(neonUtilities) 
library(stringr)
library(tidyverse)
library(lubridate)
library(here)
library(forcats)
#devtools::load_all()
```

### Switches

Decide 
1.  Get new download of the data
1.  Write data to csv in `data-raw` 

```{r switches}

wrtdata <- TRUE
dldata <- FALSE

```


## Get Data
First we download and derive the data and then later tidy and explore the data.

### Macroinverts Data Product ID
```{r DPID}
my_dpid <- 'DP1.20120.001'
```

### Choose sites
All sites had to have > 2 years of sampling data as of 2019.

```{r site choice}

my_site_list <- c('ARIK','BARC','BLWA','CARI','COMO','CRAM','CUPE','GUIL','HOPB',
                  'KING','LECO','LEWI','MAYF','OKSR','POSE','PRIN','PRLA','PRPO',
                  'REDB','SUGG','TOMB','TOOK','WALK')
```

#### Note
This is how the reproducibility gets wonky. "used data from, `r length(my_site_list)` site."

### Download Data
The below code used to download the raw macroinverts files is not run during the package build. Don't set `eval = TRUE` for a quick render! 

The manuscript data are stored in \`data/macroinverts_raw.rda` and as a `csv` in  \`data-raw/macroinvertebrates/submitted/`.

Rerun this code to update the data.

```{r down-load, eval=FALSE}
#download NEON data using API

if(dldata){ 
inv_allTabs <- loadByProduct(dpID = my_dpid, 
                             site = my_site_list,
                             package = "expanded", 
                             nCores = 4, # likely not needed
                             check.size = FALSE)
}
```

### Add taxonomy
Add to the downloaded list of data a table of taxonomy to clean up the data.
```{r taxon table}

# make ordered taxon_rank_list for a reference (subspecies is smallest rank, kingdom is largest)

taxon_rank_list_ordered <- c('kingdom', 
                             'subkingdom',
                             'infrakingdom', 
                             'superphylum', 
                             'phylum', 
                             'subphylum', 
                             'infraphylum',
                             'superdivision', 
                             'division', 
                             'subdivision', 
                             'infradivision', 
                             'parvdivision',
                             'superclass', 
                             'class',
                             'subclass',
                             'infraclass',
                             'superorder',
                             'order',
                             'suborder',
                             'infraorder',
                             'section',
                             'subsection',
                             'superfamily',
                             'family',
                             'subfamily',
                             'tribe',
                             'subtribe',
                             'genus',
                             'subgenus',
                             'speciesGroup',
                             'species',
                             'subspecies') %>% rev()
```

#### Note
This code is nor really used but could be useful. It gets a taxon table from the API and do save it in the main list.

```{r taxonomy download, eval=FALSE}
 full_taxon_table <- neonUtilities::getTaxonTable('MACROINVERTEBRATE')
```
### Load Data
If you rerun the script to scrape the NEON data, then be sure to save that new version of the data! Uncomment the code below

#### Save New Data!
```{r save data, eval=FALSE}
#---
# Uncomment to save a new version of the data

inv_allTabs <- do.call(c, 
                       list(inv_allTabs, # NEON download
                            list(full_taxon_table = full_taxon_table), # NEON dl
                            list(date_of_download = Sys.time()))) # unique id
macroinverts_raw <- inv_allTabs
use_data(macroinverts_raw, overwrite = TRUE)

#---

```

#### Load data
If you did not download a new version of the data, then here, load the data. Note the the raw csv tables are in `data-raw`
```{r load data}
#load_all() should be in the setup header
inv_allTabs <- macroinverts_raw
data.frame(tables = labels(inv_allTabs))
```

## Tidy Data
The raw data are stored in a list.

```{r check loaded list}
#names(inv_allTabs )
#names(inv_allTabs$inv_taxonomyProcessed)
# Check to see if all match
ifelse(length(setdiff(inv_allTabs$inv_taxonomyProcessed$sampleID, inv_allTabs$inv_fieldData$sampleID))>0,"STOP There is an error","All Good!")
```

### Join Data
Join the cleaned taxonomy (processed taxonomy) with the field data (sampling data). 

Make a data set with a density variable `den`. This `den` variable is what is being tested for variance and stability. 

```{r join data, eval=TRUE}
#merge/join tables: processing macroinverts data to get to density/abundance 

# join cleaned taxonomy to sample data
inv_dat <- left_join(inv_allTabs$inv_taxonomyProcessed, 
                     inv_allTabs$inv_fieldData, 
                     by = c('sampleID')) %>% 
  mutate(den = estimatedTotalCount/benthicArea) %>% # make density
  mutate(scientificName = fct_explicit_na(scientificName)) %>% # explicit missing
  dplyr::filter(sampleCondition == "condition OK") # toss samples low quality
```

### Tidy colnames.
```{r tidy inv_dat, eval=TRUE}
# remove duplicate col names and .x suffix
inv_dat <- inv_dat[,!grepl('\\.y',names(inv_dat))]
names(inv_dat) <- gsub('\\.x','',names(inv_dat))
head(inv_dat)
```
### Choose Taxonomic Scale
Toss all individuals not identified to the genus or lower taxonomic resolution (e.g., all individuals id-ed as Chironomidae are tossed).
```{r taxonomic filter}
# get genus and finer resolution using ordered taxon_rank_list
inv_dat$taxonRank_ordered <- factor(
  inv_dat$taxonRank,
  levels = taxon_rank_list_ordered,
  ordered = TRUE) 

# get all records that have rank <= genus, where genus is not NA or blank
inv_dat_fine <- inv_dat %>%
  filter(taxonRank_ordered <= 'genus') %>% # <= due to ordered factor
  filter(!is.na(genus), genus != '') # there are missing genera so toss them

# this table has all variables and it's not in a spread format yet
head(inv_dat_fine)


```

### Choose Spatial Scale
Analyses are run at a specific unit of spatial scale and that scale is the site (`siteID`).

```{r spatial scale, eval=TRUE}

# grouping variables for aggregating density/abundance. Come back here if other vars are need in the final table.
#for now, it's easier to keep simple like this in order to get one entry per site per row (species per sites summed)
my_grouping_vars <- c('siteID','genus','collectDate') #see next code chunk
```

#### Get table of GPS points
```{r GPS locations}

# getting table of location into a data.frame (lat, long, elevation)
table_location <- inv_allTabs$inv_fieldData %>%
  select(namedLocation, decimalLatitude, decimalLongitude, elevation) %>%
  distinct() %>%
  rename(
    location_id = namedLocation,
    latitude = decimalLatitude,
    longitude = decimalLongitude
    ) 

```


### Choose Temporal Scale
Analyses are run at a specific unit of rime and that scale is the year and month (bout).

```{r temporal scale}
# aggregate densities for each genus group, pull out year and month from collectDate, then
#excluding collectDate
inv_dat_aggregate_tidy <- inv_dat_fine %>%
  select(one_of(my_grouping_vars), den) %>% # spatial scale is here
  mutate(
    year = collectDate %>% lubridate::year(),
    month = collectDate %>% lubridate::month()
  ) %>%
  group_by_at(vars(my_grouping_vars, year, month)) %>%
  summarize(
    abundance = sum(den)) %>% 
  ungroup()

head(inv_dat_aggregate_tidy)

```
## Wrangle Data
Make the data in formats required for CODYN and BAT temopral analyses

### Codyn
```{r codyn, eval=TRUE}

###put in the formats required for codyn

inv_dat_aggregate_codyn <- inv_dat_fine %>%
  select(one_of(my_grouping_vars), den) %>%
  group_by_at(vars(my_grouping_vars)) %>%
  summarize(
    abundance = sum(den)) %>% # this is the unit of density analyzed
  ungroup()

head(inv_dat_aggregate_codyn)

```

### BAT
#### BAT year
```{r format BAT year}
##BAT year

agregate_year_BAT <- inv_dat_aggregate_tidy %>% 
  group_by(genus,year,siteID) %>%
  summarise(abund = mean(abundance)) %>%
  spread(genus,abund, fill = 0)

head(agregate_year_BAT)
```
#### BAT bout (month)
```{r format BAT month}
# make wide first, filling with abundance, making the 'bout' (format year+month) to be used in BAT

inv_dat_wide <- inv_dat_aggregate_tidy %>%
  tidyr::spread(genus, abundance, fill = 0)%>% 
  unite(bout,'year':'month', na.rm = TRUE, remove = FALSE)%>%
  dplyr::select(-collectDate)


head(inv_dat_wide)

```


## Write Data

### Tidy Data Write

Writes the tidy data output
```{r write tidy data, eval=TRUE}
drpath <- 'data-raw/submitted/macroinverts'

## Tidy (year and month)
if(wrtdata){
write.csv(inv_dat_aggregate_tidy, 
          file = file.path(here(), drpath, 'macroinverts_table_abundance_tidy.csv'),
          row.names = F)
}
```

### CODYN Data Write
Writes the CODYN data output

```{r write CODYN data, eval=TRUE}
## Codyn (year and month)
if(wrtdata){
write.csv(inv_dat_aggregate_codyn, 
          file = file.path(here(), drpath, 'macroinverts_table_abundance_codyn.csv'),
          row.names = F)
}
```

### BAT Year Data
Writes the BAT Year data output

```{r write BAT year data, eval=TRUE}

## BAT (year)
if(wrtdata){

write.csv(agregate_year_BAT,
          file = file.path(here(),drpath, 'macroinverts_table_abundance_year_BAT.csv'), 
          row.names = F)
}
```

### BAT Month (bout) Write
```{r write BAT month, eval=TRUE}

## BAT month
if(wrtdata){
  write.csv(inv_dat_wide, file = 
            file.path(here(),drpath, 'macroinverts_table_abundance_bout_BAT.csv'), 
            row.names = F)
}
```

### GPS Locations Write
```{r write GPS locations, eval = TRUE}

if(wrtdata){
  write.csv(table_location, file = 
            file.path(here(),drpath, 'all_inverts_table_location.csv'), row.names = F)
}

```

