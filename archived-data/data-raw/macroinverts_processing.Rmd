---
title: "Tidy NEON Macroinvertebrates Data"
output: rmarkdown::html_vignette
author: Mariana Perez Rocha, Matthew R. Helmus
vignette: >
  %\VignetteIndexEntry{Tidy NEON Macroinvertebrates Data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Aims and Scope
The aim of this document is to download and tidy data for Temporal NEON WG 14 Project.

## Setup

```{r packages, include=FALSE}
#library(temporalNEON)
library(devtools)
library(neonUtilities) 
library(stringr)
library(tidyverse)
library(lubridate)
library(here)
library(forcats)
#devtools::load_all()
```

### Switches

Decide on what you want this vignette to do
1.  Get new download of the sampling data
1.  Get new download of the taxonomy data
1.  Write downloaded data as an RDA in `data` folder
1.  Write data to csv files in `data-raw` folder
```{r switches}

dldata <-     TRUE # 1
dltaxdata <-  TRUE # 2
wrtRDAdata <- TRUE # 3
wrtcsvdata <- TRUE # 4

```


## Get Data
First we download and derive the data and then later tidy and explore the data.

### Macroinverts Data Product ID
```{r DPID}

my_dpid <- 'DP1.20120.001'

```

### Download Data
The below code used to download the raw macroinverts files is not run during the package build. Don't set `eval = TRUE` for a quick render! 

The manuscript data are stored in \`data/macroinverts_raw.rda` and as a `csv` in  \`data-raw/macroinvertebrates/submitted/`.

Rerun this code to update the data.

```{r down-load, eval=TRUE}

#download NEON data using API
if(dldata){ # UNCOMMENT THIS IF YOU WANT TO DOWNLOAD!
inv_allTabs <- loadByProduct(dpID = my_dpid, 
                            # site = my_site_list,
                             package = "expanded", 
                             nCores = 4, 
                             check.size = FALSE)

}
```

### Add taxonomy
Add to the downloaded list of data a table of taxonomy to clean up the data.
```{r taxon table}

# make ordered taxon_rank_list for a reference (subspecies is smallest rank, kingdom is largest)

taxon_rank_list_ordered <- c('kingdom', 
                             'subkingdom',
                             'infrakingdom', 
                             'superphylum', 
                             'phylum', 
                             'subphylum', 
                             'infraphylum',
                             'superdivision', 
                             'division', 
                             'subdivision', 
                             'infradivision', 
                             'parvdivision',
                             'superclass', 
                             'class',
                             'subclass',
                             'infraclass',
                             'superorder',
                             'order',
                             'suborder',
                             'infraorder',
                             'section',
                             'subsection',
                             'superfamily',
                             'family',
                             'subfamily',
                             'tribe',
                             'subtribe',
                             'genus',
                             'subgenus',
                             'speciesGroup',
                             'species',
                             'subspecies') %>% rev()
```

#### Note
This code is nor really used but could be useful. It gets a taxon table from the API and do save it in the main list.

```{r taxonomy download, eval=TRUE}

 if(dltaxdata){
   full_taxon_table <- neonUtilities::getTaxonTable('MACROINVERTEBRATE')
   }

```

#### Save New Data
```{r save data, eval=TRUE}

if(wrtRDAdata){
inv_allTabs <- do.call(c, 
                       list(inv_allTabs, # NEON download
                            list(full_taxon_table = full_taxon_table), # NEON dl
                            list(date_of_download = Sys.time()))) # unique id
macroinverts_raw <- inv_allTabs
use_data(macroinverts_raw, overwrite = TRUE)
}

```

### Load Data
If you did not download a new version of the data, then here, load the data. Note the the raw csv tables are in `data-raw`

```{r load data}

if(!dldata){
  load_all()
  inv_allTabs <- macroinverts_raw
}

data.frame(tables = labels(inv_allTabs))
```

## Tidy Data
The raw data are stored in a list.

### Check Data
```{r check loaded list}

# Check to see if all match
ifelse(
  length(
    setdiff(
      inv_allTabs$inv_taxonomyProcessed$sampleID,
      inv_allTabs$inv_fieldData$sampleID)
    )>0,
  "STOP There is an error",
  "All Good!")

```

### Join Data
Join the cleaned taxonomy (processed taxonomy) with the field data (sampling data). 

Make a data set with a density variable `den`. This `den` variable is what is being tested for variance and stability in the NEON temporal analyses. 

```{r join data, eval=TRUE}
#merge/join tables: processing macroinverts data to get to density/abundance 

# join cleaned taxonomy to sample data
inv_dat <- left_join(inv_allTabs$inv_taxonomyProcessed, 
                     inv_allTabs$inv_fieldData, 
                     by = c('sampleID')) %>% 
  mutate(den = estimatedTotalCount/benthicArea) %>% # make density
  mutate(scientificName = fct_explicit_na(scientificName)) %>% # explicit missing
  dplyr::filter(sampleCondition == "condition OK") # toss samples low quality
```

### Tidy Column Names

```{r tidy inv_dat, eval=TRUE}
# remove duplicate col names and .x suffix
inv_dat <- inv_dat[,!grepl('\\.y',names(inv_dat))]
names(inv_dat) <- gsub('\\.x','',names(inv_dat))
head(inv_dat)
```
### Choose Taxonomic Scale
Toss all individuals not identified to the genus or lower taxonomic resolution (e.g., all individuals id-ed as Chironomidae are tossed).

```{r taxonomic filter}
# get genus and finer resolution using ordered taxon_rank_list
inv_dat$taxonRank_ordered <- factor(
  inv_dat$taxonRank,
  levels = taxon_rank_list_ordered,
  ordered = TRUE) 

# get all records that have rank <= genus, where genus is not NA or blank
inv_dat_fine <- inv_dat %>%
  filter(taxonRank_ordered <= 'genus') %>% # <= due to ordered factor
  filter(!is.na(genus), genus != '') # there are missing genera so toss them

# this table has all variables and it's not in a wide format
head(inv_dat_fine)

```


### Choose Temporal Scale
Analyses are run at a specific unit of rime and that scale is the year and month (bout).

```{r temporal scale}
# aggregate densities for each genus group, pull out year and month from collectDate, then
#excluding collectDate
my_grouping_vars <- c('siteID','genus','collectDate')

inv_dat_aggregate_tidy <- inv_dat_fine %>%
  select(one_of(my_grouping_vars), den) %>% # spatial scale is here
  mutate(
    year = collectDate %>% lubridate::year(),
    month = collectDate %>% lubridate::month()
  ) %>%
  group_by_at(vars(my_grouping_vars, year, month)) %>%
  summarize(
    abundance = sum(den)) %>% 
  ungroup()

head(inv_dat_aggregate_tidy)

```

### Choose Spatial Scale
Analyses are run at a specific unit of spatial scale and that scale is the site (`siteID`).
All sites had to have at least 3 years of sampling data.

```{r site choice}

yrz <- table(inv_dat_aggregate_tidy$siteID, inv_dat_aggregate_tidy$year)>0
yrz
dim(yrz)
my_site_list <- names(rowSums(yrz))[rowSums(yrz)>2]

my_site_list
length(my_site_list)
inv_dat_fine <- inv_dat_fine %>% filter(inv_dat_fine$siteID %in% my_site_list)
inv_dat_aggregate_tidy <- inv_dat_aggregate_tidy %>% filter(siteID %in% my_site_list)

# this was from the first round of analyses before including the 2020 data
# my_site_list <- c('ARIK','BARC','BLWA','CARI','COMO','CRAM','CUPE','GUIL','HOPB',
#                   'KING','LECO','LEWI','MAYF','OKSR','POSE','PRIN','PRLA','PRPO',
#                   'REDB','SUGG','TOMB','TOOK','WALK')
```

#### Get table of GPS points
These GPS points are used when looking at the effect of latitude on variability.

```{r GPS locations}

# getting table of location into a data.frame (lat, long, elevation)
table_location <- inv_allTabs$inv_fieldData %>%
  select(namedLocation, decimalLatitude, decimalLongitude, elevation) %>%
  distinct() %>%
  rename(
    location_id = namedLocation,
    latitude = decimalLatitude,
    longitude = decimalLongitude
    ) 

```

## Wrangle Data
Make the data in formats required for CODYN and BAT temopral analyses

### Codyn
```{r codyn, eval=TRUE}

###put in the formats required for codyn


inv_dat_aggregate_codyn <- inv_dat_fine %>%
  select(one_of(my_grouping_vars), den) %>%
  group_by_at(vars(my_grouping_vars)) %>%
  summarize(
    abundance = sum(den)) %>% # this is the unit of density analyzed
  ungroup()

head(inv_dat_aggregate_codyn)

```

### BAT
#### BAT year
```{r format BAT year}
##BAT year

agregate_year_BAT <- inv_dat_aggregate_tidy %>% 
  group_by(genus,year,siteID) %>%
  summarise(abund = mean(abundance)) %>%
  spread(genus,abund, fill = 0)

head(agregate_year_BAT)
```
#### BAT bout (month)
```{r format BAT month}
# make wide first, filling with abundance, making the 'bout' (format year+month) to be used in BAT

inv_dat_wide <- inv_dat_aggregate_tidy %>%
  tidyr::spread(genus, abundance, fill = 0)%>% 
  unite(bout,'year':'month', na.rm = TRUE, remove = FALSE)%>%
  dplyr::select(-collectDate)


head(inv_dat_wide)

```


## Write Data

### Tidy Data Write

Writes the tidy data output
```{r write tidy data, eval=TRUE}
drpath <- 'data-raw/submitted/macroinverts'

## Tidy (year and month)
if(wrtcsvdata){
write.csv(inv_dat_aggregate_tidy, 
          file = file.path(here(), drpath, 'macroinverts_table_abundance_tidy.csv'),
          row.names = F)
  print("Written!")
}
```

### CODYN Data Write
Writes the CODYN data output

```{r write CODYN data, eval=TRUE}
## Codyn (year and month)
if(wrtcsvdata){
write.csv(inv_dat_aggregate_codyn, 
          file = file.path(here(), drpath, 'macroinverts_table_abundance_codyn.csv'),
          row.names = F)
  print("Written!")
}
```

### BAT Year Data
Writes the BAT Year data output

```{r write BAT year data, eval=TRUE}

## BAT (year)
if(wrtcsvdata){

write.csv(agregate_year_BAT,
          file = file.path(here(),drpath, 'macroinverts_table_abundance_year_BAT.csv'), 
          row.names = F)
    print("Written!")

}
```

### BAT Month (bout) Write
```{r write BAT month, eval=TRUE}

## BAT month
if(wrtcsvdata){
  write.csv(inv_dat_wide, file = 
            file.path(here(),drpath, 'macroinverts_table_abundance_bout_BAT.csv'), 
            row.names = F)
    print("Written!")

}
```

### GPS Locations Write
```{r write GPS locations, eval = TRUE}

if(wrtcsvdata){
  write.csv(table_location, file = 
            file.path(here(),drpath, 'all_inverts_table_location.csv'), row.names = F)
    print("Written!")

}

```

